{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6fe034f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b4916b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data): # Split data 90% training 10% testing. Assumes the first column is Y.\n",
    "    data = np.array(data)\n",
    "    m, n = data.shape\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    split_index = int(m * 0.9)\n",
    "    \n",
    "    data_train = data[:split_index].T\n",
    "    Y_train = data_train[0]\n",
    "    X_train = data_train[1:n] / (n - 1)\n",
    "\n",
    "    data_test = data[split_index:].T\n",
    "    Y_test = data_test[0]\n",
    "    X_test = data_test[1:n] / (n - 1)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "027b1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self): # Initializes weights and biases\n",
    "        np.random.seed(10)\n",
    "        self.W1 = np.random.rand(2, 30) - 0.5\n",
    "        self.b1 = np.random.rand(2, 1) - 0.5\n",
    "        \n",
    "        self.W2 = np.random.rand(2, 2) - 0.5\n",
    "        self.b2 = np.random.rand(2, 1) - 0.5\n",
    "        \n",
    "    def __ReLU(self, Z):\n",
    "        return np.maximum(Z, 0)\n",
    "    \n",
    "    def __softmax(self, Z):\n",
    "        Z = Z.astype(float)\n",
    "        A = np.exp(Z - np.max(Z)) / sum(np.exp(Z - np.max(Z)))\n",
    "        return A\n",
    "    \n",
    "    def __forward(self, X):\n",
    "        Z1 = self.W1.dot(X) + self.b1\n",
    "        A1 = self.__ReLU(Z1)\n",
    "        \n",
    "        Z2 = self.W2.dot(A1) + self.b2\n",
    "        A2 = self.__softmax(Z2)\n",
    "        return Z1, A1, Z2, A2\n",
    "\n",
    "    def __label_encoder(self, Y): # Encodes each unique value with a number\n",
    "        encoder = dict(zip(np.unique(Y), range(len(np.unique(Y)))))\n",
    "        labels = []\n",
    "        for i in Y:\n",
    "            labels.append(encoder[i])\n",
    "        \n",
    "        return np.array(labels)\n",
    "    \n",
    "    def __one_hot(self, Y):\n",
    "        Y = self.__label_encoder(Y)\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        one_hot_Y = one_hot_Y.T\n",
    "        return one_hot_Y\n",
    "    \n",
    "    def __prime_ReLU_(self, Z):\n",
    "        return Z > 0\n",
    "\n",
    "    def __backward(self, Z1, A1, Z2, A2, X, Y, learning_rate):\n",
    "        one_hot_Y = self.__one_hot(Y)\n",
    "        m, n = data.shape\n",
    "\n",
    "        dZ2 = A2 - one_hot_Y\n",
    "        dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "        db2 = 1 / m * np.sum(dZ2)\n",
    "\n",
    "        dZ1 = self.W2.T.dot(dZ2) * self.__prime_ReLU_(Z1)\n",
    "        dW1 = 1 / m * dZ1.dot(X.T)\n",
    "        db1 = 1 / m * np.sum(dZ1)\n",
    "        \n",
    "        self.W1 = self.W1 - learning_rate * dW1\n",
    "        self.b1 = self.b2 - learning_rate * db1\n",
    "        self.W2 = self.W2 - learning_rate * dW2  \n",
    "        self.b2 = self.b2 - learning_rate * db2\n",
    "                \n",
    "    def __get_predictions(self, A2): # Find largest largest predicted probability\n",
    "        return np.argmax(A2, 0)\n",
    "    \n",
    "    def __predict(self, X):\n",
    "        _, _, _, A2 = self.__forward(X)\n",
    "        return self.__get_predictions(A2)\n",
    "    \n",
    "    def __get_accuracy(self, predictions, Y):\n",
    "        return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "    def fit(self, X, Y, learning_rate, epochs):\n",
    "        accuracy = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            Z1, A1, Z2, A2 = self.__forward(X)\n",
    "            self.__backward(Z1, A1, Z2, A2, X, Y, learning_rate)\n",
    "            if i % 10 == 0:\n",
    "                accuracy.append(self.__get_accuracy(self.__predict(X), self.__one_hot(Y)[0]))\n",
    "        \n",
    "        return accuracy\n",
    "        \n",
    "    def test(self, X, Y):\n",
    "        return self.__get_accuracy(self.__predict(X), self.__one_hot(Y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b15e0629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  [0.376953125, 0.376953125, 0.388671875, 0.44140625, 0.58984375]\n",
      "Testing Accuracy:  0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "    cols = list(pd.read_csv(\"data.csv\", nrows =1))\n",
    "    data = pd.read_csv('data.csv', usecols=[i for i in cols if i != 'id' and i != 'Unnamed: 32'])\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = split_data(data)\n",
    "    \n",
    "    nn = NeuralNetwork()\n",
    "    print('Training Accuracy: ', nn.fit(X_train, Y_train, 0.001, 50))\n",
    "    \n",
    "    print('Testing Accuracy: ', nn.test(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
