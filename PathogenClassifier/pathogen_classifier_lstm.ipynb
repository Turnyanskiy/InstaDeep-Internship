{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce74131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biodatasets import list_datasets, load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be605d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into numpy array\n",
    "pathogen = load_dataset(\"pathogen\")\n",
    "\n",
    "X, y = pathogen.to_npy_arrays(input_names=[\"sequence\"], target_names=[\"class\"])\n",
    "\n",
    "pathogen.display_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1317c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Amino Acids to number\n",
    "def get_seq_column_map(X):\n",
    "    unique = set()\n",
    "    for idx, sequence in enumerate(X[0]):\n",
    "        unique.update(list(sequence))\n",
    "    \n",
    "    return dict(zip(unique, list(range(len(unique)))))\n",
    "    \n",
    "pathogen_map = get_seq_column_map(X)\n",
    "print(pathogen_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7869b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathogenDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, pathogen_map, data):\n",
    "        self.pathogen_map = pathogen_map\n",
    "        self.X = data[0]\n",
    "        self.Y = data[1]\n",
    "        \n",
    "    def __one_hot(self, Y):\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        one_hot_Y = one_hot_Y\n",
    "        return one_hot_Y.astype(np.float64)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.as_tensor([self.pathogen_map[e] for e in list(self.X[idx])]) \n",
    "        Y = self.Y[idx]\n",
    "        return X, Y\n",
    "\n",
    "def collate_padd(batch):\n",
    "        x = [row[0] for row in batch]\n",
    "        y = [row[1] for row in batch]\n",
    "        \n",
    "        sequence_len = [len(row) for row in x]\n",
    "        x =  pad_sequence(x, batch_first=True)\n",
    "        return (torch.as_tensor(x).to(torch.float32), torch.as_tensor(sequence_len)), torch.as_tensor(y).to(torch.float32)\n",
    "    \n",
    "# Split ~ 80% 10% 10%\n",
    "training_set = PathogenDataset(pathogen_map,(X[0][:80000], y[0][:80000]))\n",
    "training_loader = DataLoader(training_set, batch_size=8, shuffle=True, collate_fn=collate_padd)\n",
    "\n",
    "validation_set = PathogenDataset(pathogen_map,(X[0][80000:90000], y[0][80000:90000]))\n",
    "validation_loader = DataLoader(validation_set, batch_size=8, collate_fn=collate_padd)\n",
    "\n",
    "testing_set = PathogenDataset(pathogen_map,(X[0][90000:], y[0][90000:]))\n",
    "testing_loader = DataLoader(testing_set, batch_size=8, collate_fn=collate_padd)\n",
    "\n",
    "next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b091894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=len(pathogen_map)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=512,\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=512,\n",
    "            hidden_size=256,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        self.linear_1 = nn.Linear(\n",
    "            in_features=256,\n",
    "            out_features=128,\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "        \n",
    "        self.linear_2 = nn.Linear(\n",
    "            in_features=128,\n",
    "            out_features=1,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, sequence_len):  \n",
    "        embed = self.embed(x)\n",
    "        \n",
    "        packed_input = pack_padded_sequence(embed, sequence_len, batch_first=True, enforce_sorted=False)\n",
    "        lstm_1_seq, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(lstm_1_seq, batch_first=True)\n",
    "        \n",
    "        out_forward = output[range(len(output)), sequence_len - 1]\n",
    "        \n",
    "        dropout = self.dropout(out_forward)\n",
    "        \n",
    "        linear_1 = self.linear_1(dropout)\n",
    "        dropout = self.dropout(linear_1)\n",
    "        linear_2 = self.linear_2(dropout)\n",
    "        \n",
    "        return torch.squeeze(linear_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550796d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device : {device}\")\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "print(model)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    tqdm_bar = tqdm(training_loader, desc=f\"epoch {epoch}\", position=0)\n",
    "    \n",
    "    # Training\n",
    "    for idx, ((inputs, sequence_len), labels) in enumerate(tqdm_bar):\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        outputs = sigmoid(model(inputs.to(torch.int32), sequence_len))\n",
    "               \n",
    "        loss = criterion(outputs, labels).to(torch.float32)\n",
    "        loss.backward()\n",
    "        \n",
    "        writer.add_scalar('Loss/train', loss, idx)\n",
    "        \n",
    "        \n",
    "        # Training Accuracy\n",
    "        correct, total = 0, 0\n",
    "        predicted = torch.round(outputs.flatten())\n",
    "        y = labels\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        writer.add_scalar('accuracy/train', correct/total, idx)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    # Validation Accuracy\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, ((inputs, sequence_len), labels)  in enumerate(validation_loader):\n",
    "            correct, total = 0, 0\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = sigmoid(model(inputs.to(torch.int32), sequence_len))\n",
    "\n",
    "            predicted = torch.round(outputs.flatten())\n",
    "            y = labels\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            writer.add_scalar('accuracy/validation', correct/total, idx)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe30cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './pathogen_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632421db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Testing Accuracy\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    all_predicted, all_y = [], []\n",
    "    for ((inputs, sequence_len), labels) in testing_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        outputs = sigmoid(model(inputs.to(torch.int32), sequence_len))\n",
    "        \n",
    "        predicted = torch.round(outputs.flatten())\n",
    "        y = labels\n",
    "        \n",
    "        all_predicted.extend(predicted.tolist())\n",
    "        all_y.extend(y.tolist())\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        \n",
    "print(confusion_matrix(all_y, all_predicted))\n",
    "print(f'Accuracy of nn: {correct / total}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
